{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Visión por Computadora para Desarrollo de Videojuegos: Creando Experiencias Interactivas\"\n",
        "author: \"Jorge Ivan Romero\"\n",
        "format: \n",
        "  revealjs:\n",
        "    transition: slide\n",
        "    logo: \"logoutadeo_1.jpg\"\n",
        "    theme: \"simple\"\n",
        "    css: \"custom.css\"\n",
        "---\n",
        "\n",
        "# 1. Introducción\n",
        "\n",
        "::: {.fragment .zoom-in}\n",
        "- La **visión por computadora** es un campo de la IA que permite a las máquinas interpretar y comprender imágenes o videos.\n",
        "- Aplicada a los videojuegos, permite crear experiencias interactivas más inmersivas y dinámicas, detectando el movimiento del jugador o el entorno en tiempo real.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "# 2. ¿Cómo Funciona la Visión por Computadora en Videojuegos?\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "- **Captura de Imágenes/Videos**: Utiliza cámaras o sensores (como cámaras web o Kinect) para capturar imágenes o videos en tiempo real.\n",
        "- **Procesamiento de Imágenes**: Algoritmos de IA procesan las imágenes para detectar **movimientos**, **objetos** o **gestos** del jugador.\n",
        "- **Interacción en Tiempo Real**: El videojuego responde a las acciones detectadas, creando una experiencia interactiva única.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "# 3. Aplicaciones en Videojuegos\n",
        "\n",
        "---\n",
        "\n",
        "1. **Detección de Movimiento**:\n",
        "- Juegos que detectan el movimiento del cuerpo o de las manos del jugador para controlar personajes o elementos en el juego.\n",
        "   \n",
        " ![Detección de Movimiento](https://miro.medium.com/v2/resize:fit:720/format:webp/1*JLAnsw9NU6TFEVKKCARrCQ.gif)\n",
        "\n",
        "---\n",
        "   \n",
        "2. **Reconocimiento Facial**:\n",
        "- Juegos que adaptan la expresión facial del personaje a la del jugador.\n",
        "   \n",
        "![Reconocimiento Facial](https://mediapipe.dev/images/face_mesh_ar_effects.gif)\n",
        "\n",
        "---\n",
        "   \n",
        "3. **Reconocimiento de Gestos**:\n",
        "- El jugador controla el juego a través de gestos, como hacer señas con las manos.\n",
        "   \n",
        "![Reconocimiento de Gestos](https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F32zpz7qa8hg5gl9lyvsc.gif)\n",
        "\n",
        "---\n",
        "\n",
        "## Demo en vivo:\n",
        "[Mediapipe studio](https://mediapipe-studio.webapps.google.com/studio/demo/hand_landmarker)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 5. Ejemplo: Control de Personaje con Gestos\n",
        "\n",
        "## Paso 1: **Configuración del Juego**\n",
        "- Integra una cámara para capturar los gestos del jugador.\n",
        "\n",
        "## Paso 2: **Detección de Manos con MediaPipe**\n",
        "- El algoritmo detecta la posición de las manos del jugador.\n",
        "\n",
        "## Paso 3: **Mapeo de Gestos a Controles del Juego**\n",
        "- Se asocia cada gesto a una acción dentro del juego, como mover el personaje, saltar o atacar.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 6. Beneficios de Usar Visión por Computadora en Videojuegos\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "- **Experiencias más inmersivas**: La interacción basada en movimientos y gestos hace que el jugador se sienta más involucrado.\n",
        "- **Accesibilidad**: Los jugadores pueden usar gestos y movimientos en lugar de controles tradicionales, haciendo los juegos más accesibles para diferentes audiencias.\n",
        "- **Interacción natural**: La visión por computadora permite que la interacción sea más fluida y natural, sin necesidad de dispositivos adicionales.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "# 7. Retos de la Visión por Computadora en Videojuegos\n",
        "\n",
        "- **Precisión de Detección**: A veces, los movimientos pueden no detectarse correctamente, lo que afecta la jugabilidad.\n",
        "- **Requisitos de Hardware**: Algunos juegos requieren cámaras o sensores de alta calidad, lo que puede limitar el acceso de los jugadores.\n",
        "- **Latencia**: Para mantener una experiencia de juego fluida, es crucial minimizar la latencia entre la acción del jugador y la respuesta del juego.\n",
        "\n",
        "---\n",
        "\n",
        "# 8. Futuro de la Visión por Computadora en Videojuegos\n",
        "\n",
        "- **Realidad Aumentada (AR)**: Los juegos basados en AR están aprovechando la visión por computadora para superponer elementos digitales en el mundo real.\n",
        "- **Mejora en Sensores**: El avance de los sensores y cámaras permitirá una mejor precisión en la detección de gestos y movimientos.\n",
        "- **Integración con IA**: La inteligencia artificial mejorará la capacidad de los videojuegos para entender y reaccionar a las acciones del jugador de manera más inteligente.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "4b1ed600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "title: \"Detección de Mano con MediaPipe en Google Colab\"\n",
        "format: revealjs\n",
        "---\n",
        "\n",
        "\n",
        "## Detección de Mano con MediaPipe\n",
        "\n",
        "En esta diapositiva se mostrará el código que captura una imagen desde la cámara, detecta la mano usando MediaPipe y dibuja los landmarks.\n"
      ],
      "id": "2c2b765d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript, Image\n",
        "from base64 import b64decode\n",
        "import PIL\n",
        "import io\n",
        "\n",
        "# Función auxiliar para convertir una imagen de JavaScript a OpenCV\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "# Función para capturar una imagen usando la cámara del navegador en Google Colab\n",
        "def take_photo(quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getTracks().forEach(t => t.stop());\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    img = js_to_image(data)\n",
        "    return img\n",
        "\n",
        "# Inicializar MediaPipe para la detección de manos\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Iniciar el modelo de detección de manos\n",
        "with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7) as hands:\n",
        "    # Tomar una foto\n",
        "    img = take_photo()\n",
        "\n",
        "    # Convertir la imagen de BGR a RGB para procesar con MediaPipe\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Procesar la imagen para detectar las manos\n",
        "    results = hands.process(img_rgb)\n",
        "\n",
        "    # Si se detecta una mano, dibujar los landmarks\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "    # Convertir la imagen de BGR a RGB para mostrarla en Colab\n",
        "    img_rgb_output = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    pil_img = PIL.Image.fromarray(img_rgb_output)\n",
        "    \n",
        "    # Mostrar la imagen con los landmarks dibujados\n",
        "    display(pil_img)"
      ],
      "id": "e5f17027",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Conclusión\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "La **visión por computadora** está transformando la manera en que los jugadores interactúan con los videojuegos, permitiendo experiencias más inmersivas y accesibles. A medida que avanza la tecnología, veremos cada vez más innovaciones en la forma en que los jugadores controlan los juegos con gestos, movimientos y expresiones faciales.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "# 10. Referencias\n",
        "\n",
        "1. MediaPipe Documentation: *Real-Time Hand and Face Detection*.\n",
        "2. OpenCV Library: *Image Processing and Computer Vision*.\n",
        "3. Kinect for Windows SDK: *Real-Time Body Motion Detection*.\n",
        "\n",
        "---\n"
      ],
      "id": "da9add35"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/jorge/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}